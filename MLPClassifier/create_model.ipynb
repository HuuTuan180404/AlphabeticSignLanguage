{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bbfa0b",
   "metadata": {},
   "source": [
    "**Th∆∞ vi·ªán**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T07:28:31.097069Z",
     "start_time": "2025-07-04T07:28:29.806181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4197b52dbea19",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb1ba7ef66b495",
   "metadata": {},
   "source": [
    "**Kh·ªüi t·∫°o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41fd0d6c2164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH='../create_dataset/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81641588f5efc0ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:20:14.229390Z",
     "start_time": "2025-05-29T02:20:14.225913Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef2f10d0228cb8",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468489ebf5ad88",
   "metadata": {},
   "source": [
    "**Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298b029a3517068",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = []\n",
    "LABELS = []\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.4)\n",
    "for label in os.listdir(DATASET_PATH):\n",
    "    print('Dang xu ly class: ' + label)\n",
    "    for img_file in os.listdir(os.path.join(DATASET_PATH, label)):\n",
    "        img_path = os.path.join(DATASET_PATH, label, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        # img = cv2.resize(img, (180, 180))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        result = hands.process(img_rgb)\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                data_aux = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    data_aux.append(lm.x)\n",
    "                    data_aux.append(lm.y)\n",
    "                LABELS.append(label)\n",
    "                DATA.append(data_aux)\n",
    "        else:\n",
    "            print(f'Kh√¥ng ph√°t hi·ªán tay: {img_path}')\n",
    "hands.close()\n",
    "# L∆∞u data\n",
    "with open('MLP_data.pickle', 'wb') as f:\n",
    "    pickle.dump({'data': DATA, 'labels': LABELS}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636c0c41359435e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d967d47771f343e",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bef573c26fc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('MLP_data.pickle', 'rb'))\n",
    "DATA = data_dict['data']\n",
    "LABELS = data_dict['labels']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(DATA, LABELS, test_size=0.3, shuffle=True, stratify=LABELS)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c264cb2a",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6aef9d",
   "metadata": {},
   "source": [
    "**ƒê√°nh gi√°**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ed74e205afd89",
   "metadata": {},
   "source": [
    "*ƒê·ªô ch√≠nh x√°c*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5c2ad3c5475a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1564cd043e24f",
   "metadata": {},
   "source": [
    "*ƒê√°nh gi√° t·ª´ng ch·ªâ s·ªë*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d2822c1f93d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√°nh gi√° t·ª´ng ch·ªâ s·ªë\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"üî∏ Precision:\", round(precision * 100, 2), \"%\")\n",
    "print(\"üî∏ Recall:\", round(recall * 100, 2), \"%\")\n",
    "print(\"üî∏ F1 Score:\", round(f1 * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e9151975345bf",
   "metadata": {},
   "source": [
    "*Ma tr·∫≠n sai l·∫ßm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88121c9640be36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ConfusionMatrix.txt', 'w') as f:\n",
    "    f.write(str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376dfe05b30f381",
   "metadata": {},
   "source": [
    "*B√°o c√°o chi ti·∫øt t·ª´ng l·ªõp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1ac4f397c5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ClassificationReport.txt', 'w') as f:\n",
    "    f.write(str(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186a300d1560eb8",
   "metadata": {},
   "source": [
    "*Bi·ªÉu ƒë·ªì ch√≠nh x√°c theo t·ª´ng l·ªõp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e273bc8aaa5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.unique(y_test), per_class_acc, color='skyblue')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Per-class Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300203270f73b210",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df099b65ab5e634",
   "metadata": {},
   "source": [
    "**L∆∞u model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2950977b89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l∆∞u model\n",
    "with open('MLP_model.p', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46eca62a435b8e9",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70133198238e47b",
   "metadata": {},
   "source": [
    "**TEST qua CAMERA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ce496b5df486d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:12.913679Z",
     "start_time": "2025-05-29T02:20:21.179034Z"
    }
   },
   "outputs": [],
   "source": [
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.7)\n",
    "model = pickle.load(open('MLP_model.p', 'rb'))\n",
    "\n",
    "num_classes = len(model.classes_)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    ret, frame = cap.read()\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame,\n",
    "                                      hand_landmarks,\n",
    "                                      mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            data_aux = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                data_aux.append(lm.x)\n",
    "                data_aux.append(lm.y)\n",
    "                x_.append(lm.x)\n",
    "                y_.append(lm.y)\n",
    "\n",
    "        x1 = int(min(x_) * W)\n",
    "        y1 = int(min(y_) * H)\n",
    "        x2 = int(max(x_) * W)\n",
    "        y2 = int(max(y_) * H)\n",
    "\n",
    "        prediction = model.predict([np.array(data_aux)])\n",
    "        probs = model.predict_proba([np.asarray(data_aux)])[0]\n",
    "        current_class = prediction[0]\n",
    "\n",
    "        cv2.putText(frame, prediction[0], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    panel_height = max(H, num_classes * 30)\n",
    "    output_panel = np.ones((panel_height, 250, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        label_probs = list(zip(model.classes_, probs))\n",
    "        label_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        for idx, (label, prob) in enumerate(label_probs):\n",
    "            y_pos = 50 + idx * 24\n",
    "            cv2.putText(output_panel, f\"{label}: {prob * 100:.2f}%\", (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (W, panel_height))\n",
    "    combined = np.hstack((frame_resized, output_panel))\n",
    "    cv2.imshow('Realtime Hand Detection', combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69243e7efd07599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394d68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
